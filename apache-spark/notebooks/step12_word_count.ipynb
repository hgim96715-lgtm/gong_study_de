{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854c2d55-f728-4076-a4bf-a44c748b2751",
   "metadata": {},
   "source": [
    "## pyspark_wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db670e8-5c89-4775-b21d-0f94ae8270cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    Row,\n",
    "    SparkSession)\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b40f66d-defd-42a9-84a0-549f1beb6a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/30 05:43:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=(\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"word-count\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2012465b-0543-4ed0-bd62-bc411855519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.text(\"file:///workspace/data/word_count.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d88b14c-7eb8-429c-bea0-c1b1ac25520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|      Spark|\n",
      "|         is|\n",
      "|          a|\n",
      "|       fast|\n",
      "|distributed|\n",
      "| processing|\n",
      "|     engine|\n",
      "|      Spark|\n",
      "|         is|\n",
      "|     widely|\n",
      "|       used|\n",
      "|         in|\n",
      "|       data|\n",
      "|engineering|\n",
      "|       Data|\n",
      "|  engineers|\n",
      "|        use|\n",
      "|      Spark|\n",
      "|        for|\n",
      "|      large|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words=df.select(\n",
    "    F.explode(\n",
    "        F.split(F.col(\"value\"),' ')\n",
    "    ).alias(\"word\")\n",
    ")\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2839d7b-41bd-4e56-9076-a6e85368b501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|      Spark|   41|\n",
      "|         is|   18|\n",
      "|       data|   18|\n",
      "|           |   14|\n",
      "| processing|   10|\n",
      "|        can|    9|\n",
      "|       Data|    7|\n",
      "|        for|    7|\n",
      "|         in|    7|\n",
      "|engineering|    7|\n",
      "|  important|    5|\n",
      "|        API|    4|\n",
      "|distributed|    4|\n",
      "|  streaming|    4|\n",
      "|        use|    4|\n",
      "|       jobs|    4|\n",
      "|    systems|    4|\n",
      "|        run|    4|\n",
      "|     Hadoop|    4|\n",
      "|      makes|    3|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count=words.select(\n",
    "   F.col(\"word\")\n",
    ").groupBy(F.col(\"word\")).agg(\n",
    "    F.count(\"*\").alias(\"count\")\n",
    ").orderBy(F.col(\"count\").desc())\n",
    "count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa9084-0e1f-4c0e-8981-e221781d464c",
   "metadata": {},
   "source": [
    "### 더 보완 해야할 것이 있을까?\n",
    "\n",
    "1. 대소문자 문제\n",
    "2. 빈 문자열 문제\n",
    "3. `,`,`.` 등 문제\n",
    "\n",
    "3가지 문제를 해결해보고 개수를 다시확인해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30c71a6-7524-488f-a5a3-2569726c1664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|      Spark|\n",
      "|         is|\n",
      "|          a|\n",
      "|       fast|\n",
      "|distributed|\n",
      "| processing|\n",
      "|     engine|\n",
      "|      Spark|\n",
      "|         is|\n",
      "|     widely|\n",
      "|       used|\n",
      "|         in|\n",
      "|       data|\n",
      "|engineering|\n",
      "|       Data|\n",
      "|  engineers|\n",
      "|        use|\n",
      "|      Spark|\n",
      "|        for|\n",
      "|      large|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words=df.select(\n",
    "    F.explode(\n",
    "        F.split(F.col(\"value\"),r\"\\s+\")\n",
    "    ).alias(\"word\")\n",
    ").filter(F.col(\"word\")!=\"\")\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "183aeeb2-a0a1-447d-9c75-6a0a1346b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|      Spark|   41|\n",
      "|         is|   18|\n",
      "|       data|   18|\n",
      "| processing|   10|\n",
      "|        can|    9|\n",
      "|       Data|    7|\n",
      "|        for|    7|\n",
      "|         in|    7|\n",
      "|engineering|    7|\n",
      "|  important|    5|\n",
      "|        API|    4|\n",
      "|distributed|    4|\n",
      "|  streaming|    4|\n",
      "|        use|    4|\n",
      "|       jobs|    4|\n",
      "|    systems|    4|\n",
      "|        run|    4|\n",
      "|     Hadoop|    4|\n",
      "|      makes|    3|\n",
      "|         be|    3|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy를 실행한 직후는 GroupdData객체, 이 객체는 메서드 제공\n",
    "# 단, 이름 변경불가, 한번에 하나만 계산가능 \n",
    "count=(\n",
    "    words\n",
    "    .groupBy(\"word\")\n",
    "    .count()\n",
    "    .orderBy(F.desc(\"count\"))\n",
    ")\n",
    "count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c979a-910f-49f2-9824-c35f549e417c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
