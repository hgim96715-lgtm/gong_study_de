{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a567936a-1280-4aac-aaa3-80c46f683da6",
   "metadata": {},
   "source": [
    "## Partition vs Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6752be39-4be5-435c-9ca3-44857c2d17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    Row,\n",
    "    SparkSession)\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17dc1f3-e5d9-4b2f-9a00-6e7e0b2d8ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/02 09:59:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=(\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"spark-partition\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602aaa07-1a8a-4684-9ec4-9dcd532a55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355619db-a682-4698-bcd3-05424a1eab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition 개수확인 \n",
    "# getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca783a7e-769c-4493-886e-4f4dbc6b2e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1 파티션 개수: 1\n",
      "rdd4 파티션 개수: 4\n"
     ]
    }
   ],
   "source": [
    "# 파티션 개수 지정가능 \n",
    "rdd1=sc.parallelize(range(20),1)\n",
    "rdd4=sc.parallelize(range(20),4)\n",
    "\n",
    "print(f\"rdd1 파티션 개수: {rdd1.getNumPartitions()}\") \n",
    "print(f\"rdd4 파티션 개수: {rdd4.getNumPartitions()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d2ccda-1085-45fe-ba21-46aa9563b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파티션 내부 확인 glom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c184bcc6-d4f5-44aa-8601-b204918e4bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1 contents: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
      "rdd4 contents: [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"rdd1 contents:\", rdd1.glom().collect())\n",
    "print(\"rdd4 contents:\", rdd4.glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18d6e3f-5625-4d11-ac4c-49d97fa9f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF partitions: 5\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임도 파티션이다\n",
    "# spark.range() 자동데이터 생성기 컬럼이름은 무조건 id고정 \n",
    "# 파티션개수까지 정하기(start,end,step,partiton) \n",
    "# 0이상 20미만 1씩 증가하는 데이터를 5개 파티션에 담아줘\n",
    "df=spark.range(0,20,1,5)\n",
    "print(\"DF partitions:\", df.rdd.getNumPartitions())\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd518e4f-3207-4991-9041-468ce7e2ca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(id=0), Row(id=1), Row(id=2), Row(id=3)],\n",
       " [Row(id=4), Row(id=5), Row(id=6), Row(id=7)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파티션 내부가 너무 클때는 take사용\n",
    "df.rdd.glom().take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d170edbf-21f4-4056-bdf0-e7906b4141d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repartition vs coalesce 직접 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e59e8f20-3c86-4f25-a263-0db16ecb9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repartiton 셔플 발생 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b160534-9d3d-403b-98a9-62e90fd3ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repartition: 8\n"
     ]
    }
   ],
   "source": [
    "df_repart = df.repartition(8)\n",
    "print(\"repartition:\", df_repart.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d1c365-498d-4504-9ae6-ce18f77ee899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=true\n",
      "+- == Final Plan ==\n",
      "   ShuffleQueryStage 0\n",
      "   +- Exchange RoundRobinPartitioning(8), REPARTITION_BY_NUM, [plan_id=15]\n",
      "      +- *(1) Range (0, 20, step=1, splits=5)\n",
      "+- == Initial Plan ==\n",
      "   Exchange RoundRobinPartitioning(8), REPARTITION_BY_NUM, [plan_id=10]\n",
      "   +- Range (0, 20, step=1, splits=5)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_repart.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c318a98c-c567-4376-b669-1444d06ed0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coalesce (셔플 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd3c9e5-6df4-43b3-bcd2-58f855f10419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coalesce: 2\n"
     ]
    }
   ],
   "source": [
    "df_coal = df.coalesce(2)\n",
    "print(\"coalesce:\", df_coal.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f8675af-44b5-4a89-bd02-3906caee7dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Coalesce 2\n",
      "+- *(1) Range (0, 20, step=1, splits=5)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_coal.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24a76757-4201-4df0-8455-07041091f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파티션 수가 성능에 미치는 영향 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04c9c2f8-c7d4-422f-83d4-d2e1f225596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "big_df = spark.range(0, 50_000_000)\n",
    "\n",
    "def partition_duration(df,label):\n",
    "    start=time.time()\n",
    "    df.count()\n",
    "    end=time.time()\n",
    "    print(f\"{label}: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85149a3a-7485-4797-87da-fb72108bba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coalesce(1): 0.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 파티션 1개 \n",
    "partition_duration(\n",
    "    big_df.coalesce(1),\n",
    "    \"coalesce(1)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d96f0977-bfdc-462f-be1c-c76f014c0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=======================================>                 (7 + 3) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repartition(8): 2.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 파티션 8개로 늘리기\n",
    "partition_duration(\n",
    "    big_df.repartition(8),\n",
    "    \"repartition(8)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd86b5b6-8a1d-4bef-8ddb-f14972970245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:======================>                                  (4 + 6) / 10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repartition(200): 2.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 파티션 과다\n",
    "partition_duration(\n",
    "    big_df.repartition(200),\n",
    "    \"repartition(200)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36809f1d-5b02-49ab-8519-3e257e96dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coalesce(1): 0.71 seconds       <-- 가장 빠름! \n",
    "#repartition(8): 2.02 seconds    <--  느려짐 \n",
    "#repartition(200): 2.11 seconds  <--  더 느려짐 \n",
    "\n",
    "# 데이터가 아주 크지 않고 단순집계만 할때는 coalesce가 더 효율이 좋다는 것을 확인했다 \n",
    "# repartition이 매번 좋은 건 아니다 오히려 단순한거에서 shuffle이 발생하여 오히려 느려졌다 \n",
    "# 파티션이 과다해서 overhead가 추가되어 오히려 더 느려젔다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4489f5-a6d5-4efe-ada7-302883692b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
