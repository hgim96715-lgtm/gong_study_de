{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c618d6c-11b8-4cdf-acb3-96fe8c0987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46607989-fcf6-4ee2-8d69-50e4d158c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b08b5770-5512-4f8c-8e4f-ed1133ae99ed;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.4.3 in central\n",
      ":: resolution report :: resolve 49ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.4.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b08b5770-5512-4f8c-8e4f-ed1133ae99ed\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/2ms)\n",
      "26/02/05 05:35:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark=(\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"apache-iceberg\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c123d2d9-ee99-48e1-b0a0-e5d0b88698b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://82db49da6e17:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>apache-iceberg</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff58f59fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39728880-003e-480c-9b83-de9a59425ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DB생성\n",
    "# 카탈로그 이름(my_iceberg)을 붙여서 DB 생성\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS my_iceberg.playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fa5196-249a-4aa5-9352-f496883d7314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS my_iceberg.playground.sample_table(\n",
    "    id BIGINT,\n",
    "    data STRING\n",
    ")\n",
    "USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b961f4-9110-4237-901a-7e6efec92cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "data=[\n",
    "    (1,\"Hello World\"),\n",
    "    (2,\"Apache Iceberg\"),\n",
    "    (3, \"PySpark Demo\")\n",
    "]\n",
    "df=spark.createDataFrame(data,[\"id\",\"data\"])\n",
    "df.writeTo(\"my_iceberg.playground.sample_table\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264e40b5-1987-4143-8a98-fd5a3357c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|          data|\n",
      "+---+--------------+\n",
      "|  1|   Hello World|\n",
      "|  2|Apache Iceberg|\n",
      "|  3|  PySpark Demo|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"SELECT * FROM my_iceberg.playground.sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98fadbdd-08d3-4087-b290-6005cc8769c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE my_iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a584db4-2b4b-46c8-919f-9c2fc69f45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|          data|\n",
      "+---+--------------+\n",
      "|  1|   Hello World|\n",
      "|  2|Apache Iceberg|\n",
      "|  3|  PySpark Demo|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a003164-1035-409d-9b5c-b9efc025a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|          data|\n",
      "+---+--------------+\n",
      "|  1|   Hello World|\n",
      "|  2|Apache Iceberg|\n",
      "|  3|  PySpark Demo|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iceberg_df=spark.read.format(\"iceberg\").table(\"playground.sample_table\")\n",
    "iceberg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440bcd58-9ec3-4733-b723-31ea43aeeefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"ALTER TABLE playground.sample_table ADD COLUMN extra_info STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c45e362-fbd3-4bf2-b23c-f4814c5d0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = [\n",
    "    (4, \"Another record\", \"This is extra info\"),\n",
    "    (5, \"Yet another record\", \"Additional details\")\n",
    "]\n",
    "df_new = spark.createDataFrame(data_new, [\"id\", \"data\", \"extra_info\"])\n",
    "df_new.writeTo(\"playground.sample_table\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b9e242-b1ff-4a07-bf72-c5122c45f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+\n",
      "| id|              data|        extra_info|\n",
      "+---+------------------+------------------+\n",
      "|  1|       Hello World|              NULL|\n",
      "|  2|    Apache Iceberg|              NULL|\n",
      "|  3|      PySpark Demo|              NULL|\n",
      "|  4|    Another record|This is extra info|\n",
      "|  5|Yet another record|Additional details|\n",
      "+---+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8089ed05-6c72-4c35-af73-0a072356e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " committed_at  | 2026-02-05 05:41:03.225                                                                                                                                                                                                                                                                              \n",
      " snapshot_id   | 918297713420570779                                                                                                                                                                                                                                                                                   \n",
      " parent_id     | NULL                                                                                                                                                                                                                                                                                                 \n",
      " operation     | append                                                                                                                                                                                                                                                                                               \n",
      " manifest_list | /workspace/data/iceberg_warehouse/playground/sample_table/metadata/snap-918297713420570779-1-1dc7f9fe-336f-4fd2-92c7-d3315cee78b2.avro                                                                                                                                                               \n",
      " summary       | {spark.app.id -> app-20260205053523-0001, added-data-files -> 3, added-records -> 3, added-files-size -> 2167, changed-partition-count -> 1, total-records -> 3, total-files-size -> 2167, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} \n",
      "-RECORD 1-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " committed_at  | 2026-02-05 05:47:18.637                                                                                                                                                                                                                                                                              \n",
      " snapshot_id   | 238473521353522660                                                                                                                                                                                                                                                                                   \n",
      " parent_id     | 918297713420570779                                                                                                                                                                                                                                                                                   \n",
      " operation     | append                                                                                                                                                                                                                                                                                               \n",
      " manifest_list | /workspace/data/iceberg_warehouse/playground/sample_table/metadata/snap-238473521353522660-1-c2ef53a3-cdee-4f54-b952-5c1d091620f9.avro                                                                                                                                                               \n",
      " summary       | {spark.app.id -> app-20260205053523-0001, added-data-files -> 2, added-records -> 2, added-files-size -> 2200, changed-partition-count -> 1, total-records -> 5, total-files-size -> 4367, total-data-files -> 5, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table.snapshots\").show(truncate=False,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ea6a8bd-5116-42d1-875d-edf47d4c7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------+------------------+-------------------+\n",
      "|made_current_at        |snapshot_id       |parent_id         |is_current_ancestor|\n",
      "+-----------------------+------------------+------------------+-------------------+\n",
      "|2026-02-05 05:41:03.225|918297713420570779|NULL              |true               |\n",
      "|2026-02-05 05:47:18.637|238473521353522660|918297713420570779|true               |\n",
      "+-----------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table.history\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da62e8fd-9255-4b0c-a368-4eccceeb3534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|previous_snapshot_id|current_snapshot_id|\n",
      "+--------------------+-------------------+\n",
      "|  238473521353522660| 918297713420570779|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CALL system.rollback_to_snapshot('playground.sample_table',918297713420570779)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4ffb0f1-fae5-4b4b-935b-bd4e4c621665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+----------+\n",
      "| id|          data|extra_info|\n",
      "+---+--------------+----------+\n",
      "|  1|   Hello World|      NULL|\n",
      "|  2|Apache Iceberg|      NULL|\n",
      "|  3|  PySpark Demo|      NULL|\n",
      "+---+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec24f5f7-004c-4cbf-9a34-cfc4f5863f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------+------------------+-------------------+\n",
      "|made_current_at        |snapshot_id       |parent_id         |is_current_ancestor|\n",
      "+-----------------------+------------------+------------------+-------------------+\n",
      "|2026-02-05 05:41:03.225|918297713420570779|NULL              |true               |\n",
      "|2026-02-05 05:47:18.637|238473521353522660|918297713420570779|false              |\n",
      "|2026-02-05 05:55:12.496|918297713420570779|NULL              |true               |\n",
      "+-----------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# history 테이블을 조회해서 언제 어떤 ID가 생성됐는지 확인합니다.\n",
    "spark.sql(\"SELECT * FROM playground.sample_table.history\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "405146db-f4cb-43a2-a72c-bf6be972c1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source_snapshot_id: bigint, current_snapshot_id: bigint]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id = 238473521353522660\n",
    "spark.sql(f\"CALL system.cherrypick_snapshot('playground.sample_table', {target_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86c7a74b-cd5f-4c16-a58f-ce1b67cdd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+\n",
      "| id|              data|        extra_info|\n",
      "+---+------------------+------------------+\n",
      "|  4|    Another record|This is extra info|\n",
      "|  5|Yet another record|Additional details|\n",
      "|  1|       Hello World|              NULL|\n",
      "|  2|    Apache Iceberg|              NULL|\n",
      "|  3|      PySpark Demo|              NULL|\n",
      "+---+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM playground.sample_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1f892-e401-4987-abd1-2991409f4795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
