{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9faceb2d-eee4-4bb3-98e8-b8c2073a0aa2",
   "metadata": {},
   "source": [
    "## DPP \n",
    "Dynamic Partition Pruning\n",
    "\n",
    "1. 설정 :\n",
    "\n",
    "`spark.sql.optimizer.dynamicPartitionPruning.enabled` true (기본값)\n",
    "\n",
    "\n",
    "2. 제약사항\n",
    "\n",
    "- Fact Table이 반드시 물리적으로 파티셔닝 되어 있어야 한다.\n",
    "- 작은 테이블 쪽이 Broadcast될수 있을 만큼 작아야 효과적\n",
    "\n",
    "3. explain 확인\n",
    "\n",
    "- `dynamicpruningexpression` 이 보인다면 DPP가 성공적 작동\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d082ac-8c3a-48c0-b469-8fa13923e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    Row,\n",
    "    SparkSession)\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765e94e9-66ad-4642-8e40-3e81608ddf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/02 08:09:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=(\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"spark-DDP\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a717d104-4a3b-4366-8bfc-e266d0a8e0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark version 2.xx이면 DDP없음 3.x이상 필수\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbe9d95-d547-46ef-9bf1-e524e1944064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DDP 설정 확인 \n",
    "spark.conf.get(\"spark.sql.optimizer.dynamicPartitionPruning.enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7714e8d7-170c-4a05-a06f-8eaae9ad0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Table(작은 테이블)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219c6f37-7a15-45d7-a47f-3e7ed9cd5a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|region_id|         city|\n",
      "+---------+-------------+\n",
      "|        1|San Francisco|\n",
      "|        2|  Los Angeles|\n",
      "|        3|      Seattle|\n",
      "|        4|    San Diego|\n",
      "|        5|     New York|\n",
      "+---------+-------------+\n",
      "\n",
      "root\n",
      " |-- region_id: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimension_df=spark.read.csv(\"file:///workspace/data/ecommerce_region.csv\",\n",
    "                       header=True,\n",
    "                       inferSchema=True)\n",
    "dimension_df.show()\n",
    "dimension_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46243cb4-b20c-4ade-9b78-e5ba84fcd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact Table만들기(대용량)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efab5030-dcc2-463d-a5ea-456e4efafb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+\n",
      "|      date|            name|region|\n",
      "+----------+----------------+------+\n",
      "|2022-04-03|    Tory Delgado|     1|\n",
      "|2022-04-22|  Marivel Knight|     5|\n",
      "|2022-05-24|   Jene Franklin|     1|\n",
      "|2022-06-22|Jamison Santiago|     4|\n",
      "|2022-05-28|     Kasey Wolfe|     1|\n",
      "|2022-01-09|     Kathey Ryan|     5|\n",
      "|2022-03-30|   Elenore Moore|     2|\n",
      "|2022-10-07|  Walton Kennedy|     1|\n",
      "|2022-10-06|Lakiesha Jimenez|     1|\n",
      "|2022-01-19|  Gertude Ramsey|     3|\n",
      "|2022-12-08|   Raguel George|     4|\n",
      "|2022-01-07|      Larry Lowe|     5|\n",
      "|2022-06-13| Piedad Williams|     1|\n",
      "|2022-10-17| Melvin Mckinney|     2|\n",
      "|2022-10-17|    Cher Lambert|     3|\n",
      "|2022-12-13|    Elvina Grant|     1|\n",
      "|2022-10-27|   Cristie Stone|     1|\n",
      "|2022-01-18| Svetlana Hansen|     3|\n",
      "|2022-07-21|  Roseline Bowen|     5|\n",
      "|2022-07-03|     Lacy Flores|     1|\n",
      "+----------+----------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_schema = t.StructType([\n",
    "    t.StructField(\"date\", t.StringType(), True),\n",
    "    t.StructField(\"name\", t.StringType(), True),\n",
    "    t.StructField(\"region\", t.IntegerType(), True)])\n",
    "\n",
    "csv_file_path=\"file:///workspace/data/ecommerce_order.csv\"\n",
    "\n",
    "df=spark.read.schema(table_schema).csv(csv_file_path)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3d2615-e3e1-432e-aa0a-2a766316dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파티션 나누어 저장 \n",
    "# 파티셔닝 되어 있어야 Pruning이될수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8edd571-d0da-4d73-a2d4-b865ccc271c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .write\n",
    "    .partitionBy(\"region\")\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(\"/workspace/data/output/partition_pruning\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12f16469-cc18-4408-ade5-354caea1d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Partiton Pruning 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00304a53-1d65-4954-aec9-7ad1b3453a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+\n",
      "|      date|            name|region|\n",
      "+----------+----------------+------+\n",
      "|2022-06-22|Jamison Santiago|     4|\n",
      "|2022-12-08|   Raguel George|     4|\n",
      "|2022-08-03|   Johana Walton|     4|\n",
      "|2022-06-15|     Yi Robinson|     4|\n",
      "|2022-10-03|Lawerence Ramsey|     4|\n",
      "|2022-11-30|  Lesley Collins|     4|\n",
      "|2022-02-08|   Keneth Bailey|     4|\n",
      "|2022-10-20|    Hang Robbins|     4|\n",
      "|2022-12-08|       Wei Lewis|     4|\n",
      "|2022-01-28|   Rhona Manning|     4|\n",
      "|2022-06-23|Becki Strickland|     4|\n",
      "|2022-12-09|      Gayle Byrd|     4|\n",
      "|2022-07-18|Ellsworth Hunter|     4|\n",
      "|2022-01-18|   Luna Ferguson|     4|\n",
      "|2022-07-27| Criselda Murphy|     4|\n",
      "|2022-01-06|   Alisia Rhodes|     4|\n",
      "|2022-09-06|     Klara Gibbs|     4|\n",
      "|2022-12-18|   Irish Goodman|     4|\n",
      "|2022-04-28| Porfirio Harvey|     4|\n",
      "|2022-12-27| Andreas Spencer|     4|\n",
      "+----------+----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_df=spark.read.parquet(\"/workspace/data/output/partition_pruning\")\n",
    "read_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1070a7f-7b01-4288-9cb0-34754b7f2700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static PartitonPruning (기존)\n",
    "# 쿼리에 WHERE='' 처럼 상수가 박혀있을때만 작동했다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d100bb9d-e8c7-460d-bb80-1133887a4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "* ColumnarToRow (2)\n",
      "+- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [3]: [date#118, name#119, region#120]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/workspace/data/output/partition_pruning]\n",
      "PartitionFilters: [isnotnull(region#120), (region#120 = 2)]\n",
      "ReadSchema: struct<date:string,name:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [3]: [date#118, name#119, region#120]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DPP x\n",
    "read_df.where(\"region=2\").explain(\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "075a4d81-a5f7-4ec7-aaec-ace1ed9fbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPP 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ccb23f9-1308-45c2-98e3-24954e3b1f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+---------+-------------+\n",
      "|      date|            name|region|region_id|         city|\n",
      "+----------+----------------+------+---------+-------------+\n",
      "|2022-04-03|    Tory Delgado|     1|        1|San Francisco|\n",
      "|2022-05-24|   Jene Franklin|     1|        1|San Francisco|\n",
      "|2022-05-28|     Kasey Wolfe|     1|        1|San Francisco|\n",
      "|2022-10-07|  Walton Kennedy|     1|        1|San Francisco|\n",
      "|2022-10-06|Lakiesha Jimenez|     1|        1|San Francisco|\n",
      "|2022-06-13| Piedad Williams|     1|        1|San Francisco|\n",
      "|2022-12-13|    Elvina Grant|     1|        1|San Francisco|\n",
      "|2022-10-27|   Cristie Stone|     1|        1|San Francisco|\n",
      "|2022-07-03|     Lacy Flores|     1|        1|San Francisco|\n",
      "|2022-01-01|   Kathey Little|     1|        1|San Francisco|\n",
      "|2022-04-13|        Fe Reyes|     1|        1|San Francisco|\n",
      "|2022-06-23|   Apryl Holland|     1|        1|San Francisco|\n",
      "|2022-07-13|  Doloris Farmer|     1|        1|San Francisco|\n",
      "|2022-07-12| Merrie Erickson|     1|        1|San Francisco|\n",
      "|2022-09-17|     Ilda Turner|     1|        1|San Francisco|\n",
      "|2022-03-20|   Porter Sutton|     1|        1|San Francisco|\n",
      "|2022-02-10|Garfield Gardner|     1|        1|San Francisco|\n",
      "|2022-07-25|      Janay Gill|     1|        1|San Francisco|\n",
      "|2022-01-11|   Benton Brooks|     1|        1|San Francisco|\n",
      "|2022-02-07|  Cleora Baldwin|     1|        1|San Francisco|\n",
      "+----------+----------------+------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df=read_df.join(\n",
    "    F.broadcast(dimension_df),\n",
    "     read_df.region == dimension_df.region_id,\n",
    "    \"inner\"\n",
    ").where(dimension_df.city==\"San Francisco\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b95bf216-2b9e-4a89-aa40-5e7f426c3050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (6)\n",
      "+- BroadcastHashJoin Inner BuildRight (5)\n",
      "   :- Scan parquet  (1)\n",
      "   +- BroadcastExchange (4)\n",
      "      +- Filter (3)\n",
      "         +- Scan csv  (2)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [3]: [date#118, name#119, region#120]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/workspace/data/output/partition_pruning]\n",
      "PartitionFilters: [isnotnull(region#120), dynamicpruningexpression(region#120 IN dynamicpruning#173)]\n",
      "ReadSchema: struct<date:string,name:string>\n",
      "\n",
      "(2) Scan csv \n",
      "Output [2]: [region_id#50, city#51]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/workspace/data/ecommerce_region.csv]\n",
      "PushedFilters: [IsNotNull(city), EqualTo(city,San Francisco), IsNotNull(region_id)]\n",
      "ReadSchema: struct<region_id:int,city:string>\n",
      "\n",
      "(3) Filter\n",
      "Input [2]: [region_id#50, city#51]\n",
      "Condition : ((isnotnull(city#51) AND (city#51 = San Francisco)) AND isnotnull(region_id#50))\n",
      "\n",
      "(4) BroadcastExchange\n",
      "Input [2]: [region_id#50, city#51]\n",
      "Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=271]\n",
      "\n",
      "(5) BroadcastHashJoin\n",
      "Left keys [1]: [region#120]\n",
      "Right keys [1]: [region_id#50]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(6) AdaptiveSparkPlan\n",
      "Output [5]: [date#118, name#119, region#120, region_id#50, city#51]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "===== Subqueries =====\n",
      "\n",
      "Subquery:1 Hosting operator id = 1 Hosting Expression = region#120 IN dynamicpruning#173\n",
      "AdaptiveSparkPlan (9)\n",
      "+- Filter (8)\n",
      "   +- Scan csv  (7)\n",
      "\n",
      "\n",
      "(7) Scan csv \n",
      "Output [2]: [region_id#50, city#51]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/workspace/data/ecommerce_region.csv]\n",
      "PushedFilters: [IsNotNull(city), EqualTo(city,San Francisco), IsNotNull(region_id)]\n",
      "ReadSchema: struct<region_id:int,city:string>\n",
      "\n",
      "(8) Filter\n",
      "Input [2]: [region_id#50, city#51]\n",
      "Condition : ((isnotnull(city#51) AND (city#51 = San Francisco)) AND isnotnull(region_id#50))\n",
      "\n",
      "(9) AdaptiveSparkPlan\n",
      "Output [2]: [region_id#50, city#51]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff6f8f-51b4-4117-8b8b-439d69183498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
