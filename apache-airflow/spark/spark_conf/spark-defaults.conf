# 1. 이벤트 로그 설정 (History Server용)
spark.eventLog.enabled           true
spark.eventLog.dir               file:/tmp/spark-events
spark.history.fs.logDirectory    file:/tmp/spark-events

# 2. 필수 라이브러리 (S3/MinIO 연결용)
spark.jars.packages              org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262

# 3. MinIO 연결 설정 (중요: 이제 같은 네트워크라 'minio'라고 부릅니다!)
spark.hadoop.fs.s3a.endpoint          http://minio:9000
spark.hadoop.fs.s3a.access.key        ROOTNAME
spark.hadoop.fs.s3a.secret.key        CHANGEME123
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.impl              org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.connection.ssl.enabled false

# 4. Java 17 대응 보안 옵션 (이거 없으면 Spark 죽습니다!)
# (Ivy 설정 뒤에 --add-opens 옵션들을 쭉 이어 붙였습니다)
spark.driver.extraJavaOptions    -Divy.cache.dir=/tmp/ivy2 -Divy.home=/tmp/ivy2 --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED

# Executor(일꾼)에게도 똑같이 적용
spark.executor.extraJavaOptions  --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED



# [중요] Airflow(Driver)와 Spark(Worker)가 통신할 고정 포트
spark.driver.port                20000
spark.blockManager.port          20001

# [중요] Spark가 Airflow를 찾을 때 사용할 주소 (Docker Service 이름)
spark.driver.host                airflow-worker
spark.driver.bindAddress         0.0.0.0